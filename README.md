ğŸš€ Zero-Downtime Blueâ€“Green Deployment with Docker & Nginx

This project demonstrates a true zero-downtime Blueâ€“Green deployment strategy on a single EC2 instance using Docker and Nginx (open-source) â€” without relying on polling scripts, sleep-based health checks, or cloud load balancers.

The deployment guarantees that users never experience 5xx errors, even when the active version fails.

ğŸ¯ Problem Statement

In a traditional Docker-based deployment on a single server:

Only one version of the app runs at a time

Deployments cause downtime

Rollbacks are slow and reactive

Health-check scripts introduce delay and instability

This project solves those problems by moving failover logic into the reverse proxy layer.

ğŸ§  Key Idea (What Makes This Different)

Zero downtime cannot be reliably achieved with reactive scripts.
It must be enforced at the proxy level, per request.

Instead of:

monitoring the app

waiting for failure

switching traffic later

We let Nginx handle failures instantly at request time.

ğŸ—ï¸ Architecture Overview

Blue â†’ Stable (old) version

Green â†’ New version (primary)

Nginx â†’ Reverse proxy + failover controller

Both Blue and Green containers run simultaneously on the same Docker network.

Traffic Flow
Client â†’ Nginx â†’ Green (primary)
                    â†“
             (failure detected)
                    â†“
           Nginx retries same request â†’ Blue


âœ” Same request
âœ” No delay
âœ” No error shown to user

âš™ï¸ How Zero Downtime Is Achieved

This setup uses request-level failover, not traffic switching.

Key Nginx mechanisms used:

backup upstream

Fast upstream timeouts

Immediate retry on failure

No polling or health-check loops

No container restarts during failover

ğŸ“„ Final Nginx Configuration
events {}

http {

  upstream app_backend {
    server green:80 max_fails=1 fail_timeout=0;
    server blue:80 backup;
  }

  server {
    listen 80;

    location / {
      proxy_pass http://app_backend;

      proxy_http_version 1.1;
      proxy_set_header Connection "";

      proxy_connect_timeout 1s;
      proxy_send_timeout   1s;
      proxy_read_timeout   1s;

      proxy_next_upstream_timeout 0;
      proxy_next_upstream error timeout http_500 http_502 http_503 http_504;
      proxy_next_upstream_tries 2;
    }
  }
}

ğŸ” Deployment & Rollback Behavior
Normal Operation

Green serves all traffic

Blue stays idle as rollback target

Failure Scenario

First failed request on Green

Nginx retries the same request on Blue

User receives a valid response

Green is permanently avoided until manual redeploy

Recovery

Fix Green

Restart Green container

Reload Nginx

Green becomes primary again

No scripts. No delay. No downtime.

ğŸ§ª How to Test Zero Downtime
docker stop green


Expected result:

Website continues loading

No 502 / 504 errors

Page switches to Blue instantly

âŒ Why Health-Check Scripts Were Removed

Earlier approaches used scripts like:

curl checks

sleep-based polling

config rewrites on failure

These are reactive and always allow a failure window.

This project removes them entirely because:

Scripts react after users are affected

Nginx can retry requests before responding

Proxy-level failover is deterministic and instant

ğŸ§© Scope & Limitations

This guarantees zero downtime for:

Container crashes

Network timeouts

Backend 5xx errors

It does not protect against:

Logical bugs that still return 200 OK

(No system can.)

ğŸ“¦ Tech Stack

Docker

Docker Compose

Nginx (open source)

Ubuntu (EC2 Free Tier compatible)

ğŸ™ Credits & Acknowledgements

This project is inspired by and builds upon the ideas from the original repository:

Original Repo:
ğŸ‘‰ https://github.com/startbootstrap/startbootstrap-landing-page
This is the source repo used for making this project.

ğŸ Conclusion

This project demonstrates how real-world zero-downtime deployments are achieved:

Not with sleep loops

Not with reactive scripts

But with fail-fast proxies and request retries

This approach mirrors how production systems using ALB, HAProxy, and Envoy work internally.
